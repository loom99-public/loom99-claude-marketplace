# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

The **dev-loop** plugin provides structured development workflow commands and agents for Claude Code. It implements two core workflows:

1. **Test-Driven Development (TDD)**: `/evaluate-and-plan` + `/test-and-implement` - writes tests first, then implements
2. **Iterative Implementation**: `/evaluate-and-plan` + `/implement-and-iterate` - implements and validates through runtime evaluation

Both workflows share a common evaluation/planning foundation but differ in validation approach.

## Architecture

### Planning Document System

All workflow state lives in `.agent_planning/` directory:

**READ-ONLY files** (authoritative sources):
- `PROJECT_SPEC.md` / `PROJECT.md` - Project requirements and specifications
- `STATUS-<YYYY-MM-DD-HHmmss>.md` - Current implementation state (generated by project-evaluator)
- `PLAN-<YYYY-MM-DD-HHmmss>.md` - Work backlog (generated by status-planner)

**READ-WRITE files** (working documents):
- `BACKLOG*.md`, `SPRINT*.md`, `TODO*.md` - Tracked by agents during implementation

**File retention**: Max 4 timestamped files per prefix (STATUS, PLAN). Oldest automatically deleted.

### Workflow Integration

The workflows follow an **agent coordination pattern**:

```
User Request
     ↓
Command (slash command) - Orchestrates agent sequence
     ↓
Agents (specialized) - Execute individual phases
     ↓
Planning Docs (.agent_planning/) - Shared state
```

## Core Workflows

### Workflow 1: TDD Workflow (`/evaluate-and-plan` → `/test-and-implement`)

**Phases**:
1. **Evaluate**: project-evaluator → STATUS-*.md (gap analysis, completion metrics)
2. **Plan**: status-planner → PLAN-*.md (prioritized backlog from STATUS)
3. **Test**: functional-tester → writes un-gameable functional tests
4. **Implement**: test-driven-implementer → implements until tests pass

**Key principle**: Tests define the contract. Implementation must pass tests through real functionality, never shortcuts.

**When to use**: Features with clear requirements that can be validated programmatically.

### Workflow 2: Non-TDD Workflow (`/evaluate-and-plan` → `/implement-and-iterate`)

**Phases**:
1. **Evaluate**: project-evaluator → STATUS-*.md
2. **Plan**: status-planner → PLAN-*.md
3. **Implement Loop**:
   - iterative-implementer → builds functionality incrementally
   - work-evaluator → validates with runtime evidence (screenshots, logs, execution)
   - Repeat until goals achieved

**Key principle**: Validation through manual testing and runtime evaluation, not automated tests.

**When to use**: UI/visual features, exploratory work, or when tests are impractical upfront.

## Agent Responsibilities

### project-evaluator (evaluator)
- **Input**: PROJECT_SPEC.md, codebase
- **Output**: STATUS-<timestamp>.md
- **Mission**: Ruthless gap analysis. Zero-optimism assessment of what exists vs. spec.
- **Evidence**: File paths, line numbers, quantifiable metrics ("2 of 12 tools implemented")

### status-planner (planner)
- **Input**: STATUS-*.md (latest), PROJECT_SPEC.md
- **Output**: PLAN-<timestamp>.md, SPRINT-<timestamp>.md
- **Mission**: Convert gaps into prioritized backlog with acceptance criteria
- **Cleanup**: Archives stale/contradictory planning docs

### functional-tester (TDD only)
- **Input**: PLAN-*.md, STATUS-*.md
- **Output**: Test files (tests/functional/*)
- **Mission**: Write high-level functional tests validating real user workflows
- **Anti-gaming**: Tests must verify actual behavior, not implementation details. Cannot pass with stubs.

### test-driven-implementer (TDD only)
- **Input**: Failing tests, PLAN-*.md, STATUS-*.md
- **Output**: Implementation code, commits
- **Mission**: Implement real functionality to pass tests. No shortcuts, no test modification.
- **Quality**: Clean code, proper error handling, maintainable design

### iterative-implementer (Non-TDD only)
- **Input**: PLAN-*.md, STATUS-*.md
- **Output**: Implementation code, commits
- **Mission**: Build working functionality incrementally without tests upfront
- **Focus**: Real features, frequent commits, quality engineering

### work-evaluator (Non-TDD only)
- **Input**: PLAN-*.md acceptance criteria
- **Output**: WORK-EVALUATION-<timestamp>.md
- **Mission**: Runtime validation - run software, capture evidence, assess goals
- **Evidence**: Screenshots and browser metadata (chrome-devtools for web apps), logs, command output

### product-visionary (feature proposals)
- **Input**: Current state, user needs
- **Output**: Feature proposals
- **Mission**: Design high-value features that are innovative yet pragmatic

## Command Reference

### `/evaluate-and-plan [area of focus]`
1. Runs project-evaluator → STATUS-*.md
2. Runs status-planner → PLAN-*.md

**Use**: Start any workflow. Re-run after major changes to sync planning docs.

### `/test-and-implement [area of focus | "plan-first"]`
**TDD workflow**:
1. Optional: Run `/evaluate-and-plan` if "plan-first" or no STATUS/PLAN exists
2. **TestLoop**: functional-tester writes tests → project-evaluator validates tests meet criteria
3. **ImplementLoop**: test-driven-implementer implements → project-evaluator validates implementation
4. Final: Re-run `/evaluate-and-plan` to update status

**Exit conditions**:
- TestLoop: Tests meet all TestCriteria (useful, complete, flexible, automated)
- ImplementLoop: No outstanding issues with well-defined solutions

### `/implement-and-iterate [area of focus | "plan-first"]`
**Non-TDD workflow**:
1. Optional: Run `/evaluate-and-plan` if "plan-first" or no STATUS/PLAN exists
2. **Loop**:
   - iterative-implementer → implements incrementally
   - work-evaluator → validates with runtime evidence
3. Final: Re-run `/evaluate-and-plan` to update status

**Exit conditions**:
- COMPLETE: work-evaluator confirms all goals achieved
- INCOMPLETE with clear path: Continue loop
- BLOCKED: Pause, request user guidance

### `/feature-proposal [feature description]`
1. Runs product-visionary → proposal document
2. Creates forward-thinking, pragmatic feature designs

## Critical Rules

### For All Agents

1. **File Management**: All planning work in `.agent_planning/`. Never modify completed work files.
2. **Honesty**: No optimism, no shortcuts, no placeholders in production code
3. **Evidence**: Always cite file paths, line numbers, metrics
4. **Timestamping**: Use `YYYY-MM-DD-HHmmss` format consistently

### For Test Writing (TDD workflow)

1. **Never use MagicMock()** for external systems - use real objects with selective patching or `create_autospec`
2. **Never invent attributes/methods** that don't exist in real APIs
3. **Tests must fail with stubs** - un-gameable by design
4. **Validate real user workflows** - end-to-end, not implementation details

### For Implementation (Both workflows)

1. **No hardcoded test values** or test-specific branches
2. **No TODO comments** in completed code
3. **Explicit error handling** - no silent failures
4. **Real functionality** - no shortcuts to pass tests/validation

## Development Tips

### Starting a New Feature

```bash
# TDD approach
/evaluate-and-plan "user authentication"
/test-and-implement

# Non-TDD approach
/evaluate-and-plan "dashboard UI"
/implement-and-iterate
```

### Mid-Development Status Check

```bash
# Re-evaluate and update plans
/evaluate-and-plan
```

### Understanding Current State

1. Read `.agent_planning/STATUS-*.md` (latest timestamp) for implementation gaps
2. Read `.agent_planning/PLAN-*.md` (latest timestamp) for prioritized backlog
3. Check `SPRINT-*.md` or `TODO-*.md` for immediate work items

### Debugging Workflow Issues

**Tests pass but production fails**:
- Check functional-tester used real objects, not MagicMock with invented APIs
- Tests should fail if implementation uses wrong/non-existent APIs

**Implementation seems incomplete**:
- Check project-evaluator STATUS report for INCOMPLETE/PARTIAL/STUB_ONLY markers
- Review PLAN acceptance criteria - all must be met

**Planning docs contradict each other**:
- Use latest timestamped files (highest YYYY-MM-DD-HHmmss)
- status-planner should archive stale docs to `.agent_planning/archive/`

## Integration Points

### MCP Servers

The dev-loop plugin configures the chrome-devtools MCP server via `.mcp.json`:

**chrome-devtools** (browser automation + metadata):
- Used by: work-evaluator (web UI evidence gathering)
- Purpose: Navigate browser, capture screenshots, extract console logs/network errors for browser-based applications
- When: Web UI features in non-TDD workflow during runtime evaluation

**Integration Philosophy**: "Light touch" - chrome-devtools integrated at pivotal workflow points (runtime verification, evidence gathering) with minimal prompt additions. The work-evaluator agent uses screenshots and browser metadata as evidence alongside logs and errors when evaluating web applications.

### Git Workflow
- Agents use GitAdd, GitCommit tools
- Commits follow conventional format: `feat(component): description`
- Implementation commits include test names that now pass

### Planning Document Provenance
Generated files include header noting:
- Source STATUS/PLAN files and timestamps
- Spec version/hash
- Generation timestamp

## Common Patterns

### Loop Exit Decisions

Both workflows use loops with explicit exit conditions:

**TDD TestLoop**: Exit when tests meet all criteria (project-evaluator confirms)
**TDD ImplementLoop**: Exit when no well-defined issues remain (project-evaluator confirms)
**Non-TDD Loop**: Exit when work-evaluator returns COMPLETE status

**CRITICAL**: All loops end with an EVALUATE step - never skip evaluation.

### Agent Handoffs

Commands orchestrate multi-agent sequences:
1. Command receives user input + arguments
2. Command expands to prompt with agent invocations
3. First agent completes, produces output
4. "Only after [agent] completes, use [next agent]..." ensures sequence
5. Final agent often re-runs `/evaluate-and-plan` to update state

### File Retention

Automatic cleanup prevents planning drift:
- Keep max 4 timestamped files per prefix (STATUS-*, PLAN-*)
- Delete oldest when generating new file
- Archive contradictory/stale planning docs to `.agent_planning/archive/`

## Quality Standards

### project-evaluator Output
- Conservative completion percentages
- Quantified gaps ("3 of 12", "0% coverage")
- Status taxonomy: NOT_STARTED | STUB_ONLY | PARTIAL | INCOMPLETE | COMPLETE
- Runtime verification: Run code, don't just inspect

### functional-tester Output
- Tests mirror real user workflows (CLI commands, API calls, UI interactions)
- Validate observable outcomes users see
- Multiple verification points per test (result + side effects + state)
- Real execution paths, not mocks of tested functionality

### Implementation Output
- Clean, maintainable, production-quality code
- Explicit error handling with helpful messages
- Low cyclomatic complexity
- Follows language idioms and best practices
- No placeholders, TODOs, or stub implementations

## File Structure

```
plugins/dev-loop/
├── .claude-plugin/
│   └── plugin.json          # Plugin manifest
├── agents/
│   ├── functional-tester.md       # Test design/writing (TDD)
│   ├── iterative-implementer.md   # Incremental implementation (non-TDD)
│   ├── product-visionary.md       # Feature proposals
│   ├── project-evaluator.md       # Gap analysis → STATUS
│   ├── status-planner.md          # Backlog generation → PLAN
│   ├── test-driven-implementer.md # TDD implementation
│   └── work-evaluator.md          # Runtime validation (non-TDD)
├── commands/
│   ├── evaluate-and-plan.md       # Shared: evaluator + planner
│   ├── feature-proposal.md        # Feature design
│   ├── implement-and-iterate.md   # Non-TDD workflow
│   └── test-and-implement.md      # TDD workflow
└── CLAUDE.md                      # This file
```

## Philosophy

**Brutal honesty saves projects**. The workflows enforce reality-based development:

- **TDD**: Tests fail if functionality is faked → forces real implementation
- **Non-TDD**: Runtime evaluation fails if goals unmet → forces working software
- **Evaluation**: Zero-optimism gap analysis → exposes actual state
- **Planning**: Evidence-based backlog → tracks what remains

No shortcuts. No optimism. Just working software.

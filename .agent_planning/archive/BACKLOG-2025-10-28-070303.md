# Project Backlog: loom99-claude-marketplace

**Generated**: 2025-10-28 07:03:03
**Source STATUS**: STATUS-2025-10-28-065832.md
**Spec Version**: CLAUDE.md (current)
**Current Completion**: 58% (Sprint 2 Week 1 Complete)
**Target**: Functional 3-plugin marketplace with testing and documentation

---

## Executive Summary

Sprint 2 Week 1 achieved exceptional implementation progress (P1-3, P1-4, P1-5, P1-6 delivered), moving from 35% to 58% completion. However, **CRITICAL GAPS** emerged:

1. **ZERO testing performed** - 5,752 lines of implementation code with no execution evidence
2. **Documentation severely outdated** - CLAUDE.md still claims "skeleton/placeholder phase"
3. **No README files** - Users cannot install or use the marketplace
4. **epti incomplete** - Skills and hooks still missing

**Sprint 2 Week 1 Achievements**:
- ‚úÖ agent-loop 100% COMPLETE (skills + hooks added, 2,311 total lines)
- ‚úÖ epti 60% COMPLETE (agent + commands added, 3,441 total lines)
- ‚úÖ All configuration files remain 100% valid
- ‚úÖ 4 of 4 planned P1 items delivered

**Sprint 2 Week 2 CRITICAL PRIORITIES**:
1. **IMMEDIATE**: Execute manual testing (P2-5) - Cannot ship untested code
2. **HIGH**: Update CLAUDE.md (P2-7) - Currently misleading AI assistants and developers
3. Complete epti plugin (P1-7, P1-8) - Bring to 100% like agent-loop
4. Create essential documentation (P2-1, P2-2, P2-3) - Enable user adoption
5. Test epti plugin (P2-6) - Verify TDD workflow works

**Total Remaining Work Items**: 22 (down from 26)
**Estimated Effort to MVP**: 35-50 hours (down from 40-54 hours)

---

## P0 (CRITICAL) - Immediate Action Required

### P0-1: URGENT - Execute Manual Testing for agent-loop (Was P2-5)

**Status**: Not Started ‚ö†Ô∏è **BLOCKING SPRINT COMPLETION**
**Effort**: Small (2 hours)
**Dependencies**: None (P1-3, P1-4 already complete)
**Spec Reference**: Testing requirement ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 160-173, 320-355, 564-575

#### Description
**CRITICAL**: agent-loop has 2,311 lines of implementation code with ZERO execution evidence. Cannot declare work "complete" without testing. Must execute manual testing protocol IMMEDIATELY to verify plugin actually loads and works.

#### Acceptance Criteria
- [ ] Test plan created for agent-loop workflow
- [ ] Manual test executed: full explore‚Üíplan‚Üícode‚Üícommit workflow
- [ ] Each command (/explore, /plan, /code, /commit) tested individually
- [ ] Skills verified to be invocable and provide value
- [ ] Hooks tested (pre-commit, post-code, commit-msg)
- [ ] Agent guidance verified at each stage
- [ ] Test results documented with screenshots/observations
- [ ] Any issues discovered filed as backlog items

#### Technical Notes
**Test Scenario**: "Add a helper function to calculate business days between two dates"

**Execution Steps**:
1. Load marketplace in Claude Code environment
2. Install agent-loop plugin
3. Execute /explore on sample project - verify explores without coding
4. Execute /plan - verify plan document created
5. Execute /code - verify implementation follows plan
6. Execute /commit - verify git operations and hooks
7. Document ALL results, observations, and issues

**WHY CRITICAL**:
- 2,311 lines of code with zero execution evidence
- Unknown if plugin actually loads without errors
- Unknown if commands are accessible
- Unknown if hooks trigger correctly
- Cannot proceed with confidence until verified

---

### P0-2: URGENT - Update CLAUDE.md to Reflect Reality (Was P2-7)

**Status**: Not Started ‚ö†Ô∏è **ACTIVELY HARMFUL**
**Effort**: Small (1 hour)
**Dependencies**: None
**Spec Reference**: Documentation accuracy ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 184-223, 578-584

#### Description
**CRITICAL**: CLAUDE.md is severely outdated and actively misleading. Line 85 states plugins are in "skeleton/placeholder phase" when agent-loop is 100% complete (2,311 lines) and epti is 60% complete (3,441 lines). This misleads both human developers and AI assistants about project state.

#### Acceptance Criteria
- [ ] Line 85 "skeleton/placeholder phase" statement REMOVED
- [ ] Plugin status updated: agent-loop "100% Complete", epti "60% Complete", visual-iteration "15%"
- [ ] Current Plugins section updated with actual command names
- [ ] Document agent-loop as functional with 4 commands, 4 skills, 3 hooks
- [ ] Document epti as partial: agent + 6 commands implemented, skills/hooks pending
- [ ] Document visual-iteration as structure-only (no implementation)
- [ ] Update Development Workflow section with current practices
- [ ] Ensure all paths and references correct

#### Technical Notes
**Specific Changes Required**:
- Section "Current Plugins" (lines 84-94): Replace "Early development, skeleton structure in place" with actual status
- Add actual command names: agent-loop (/explore, /plan, /code, /commit), epti (/write-tests, /verify-fail, /commit-tests, /implement, /iterate, /commit-code)
- Update line counts and implementation status
- Remove all "placeholder" language

**WHY CRITICAL**:
- AI assistants use CLAUDE.md to understand project state
- Currently tells AI the project is in "skeleton phase" when it's 58% complete
- Actively causes confusion and incorrect planning
- High-value, low-effort fix

---

## P1 (High) - Core Plugin Implementation

### P1-7: Implement epti Skills

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: None (P0-2 epti agent complete)
**Spec Reference**: CLAUDE.md lines 19-30 ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 79, 92, 98-100, 403-410

#### Description
Create reusable skills for TDD workflow to match agent-loop's skill quality (1,763 lines). Skills needed: test generation from requirements, test execution and parsing, safe implementation with test protection, overfitting detection via subagents, and test framework detection.

#### Acceptance Criteria
- [ ] Skill for test generation from requirements created (test-gen.md)
- [ ] Skill for test execution and result parsing created (test-exec.md)
- [ ] Skill for implementation with test-protection created (implement-safe.md)
- [ ] Skill for detecting test overfitting created (overfit-detect.md)
- [ ] Skill for test framework detection created (framework-detect.md)
- [ ] All skills in plugins/epti/skills/
- [ ] Skills documented with clear usage examples
- [ ] Skills work with multiple test frameworks (pytest, jest, go test minimum)
- [ ] .gitkeep removed from skills directory

#### Technical Notes
**Framework Detection Order**:
1. Look for config files (pytest.ini, jest.config.js, go.mod)
2. Check package files (package.json with jest, setup.py with pytest)
3. Check file patterns (*_test.py, *.test.js, *_test.go)

**Overfitting Detection**: Critical skill - use subagents to verify implementation solves actual problem, not just satisfies test cases. Independent validation prevents "testing the tests."

**Estimated Lines**: ~1,500-2,000 lines based on agent-loop skills pattern

---

### P1-8: Configure epti Test Runner Hooks

**Status**: Not Started
**Effort**: Small (2-3 hours)
**Dependencies**: P1-7 (test execution skill)
**Spec Reference**: CLAUDE.md line 27 ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 80, 93, 98-100, 403-410

#### Description
Configure hooks to automatically run tests after code changes, prevent commits when tests fail, and enforce TDD discipline. Bring epti to 100% completion matching agent-loop.

#### Acceptance Criteria
- [ ] hooks.json contains test automation hooks (minimum 3)
- [ ] Hook: afterTestWrite - verifies tests fail before implementation
- [ ] Hook: afterCodeChange - runs test suite automatically
- [ ] Hook: beforeCommit - blocks commits if tests fail
- [ ] Hooks detect test framework automatically
- [ ] Hook failures provide clear, actionable error messages
- [ ] Hooks are documented
- [ ] Hooks tested and confirmed working

#### Technical Notes
**Hook Configuration Pattern** (similar to agent-loop):
```json
[
  {
    "event": "afterTestWrite",
    "command": "./scripts/run-tests.sh --verify-fail",
    "description": "Verify tests fail before implementation"
  },
  {
    "event": "afterCodeChange",
    "command": "./scripts/run-tests.sh",
    "description": "Run tests after code changes"
  },
  {
    "event": "beforeCommit",
    "command": "./scripts/run-tests.sh --block-on-fail",
    "description": "Prevent commit if tests fail"
  }
]
```

May require creating `scripts/run-tests.sh` with framework detection.

**Upon Completion**: epti reaches 100% (matching agent-loop)

---

### P1-9: Implement visual-iteration Main Agent

**Status**: Not Started
**Effort**: Large (6-8 hours)
**Dependencies**: None (P0-4, P0-5 from Sprint 1 complete)
**Spec Reference**: CLAUDE.md lines 32-41 ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 104, 119-123, 422-426

#### Description
Create agent for visual-iteration plugin implementing "Write code ‚Üí Screenshot result ‚Üí Iterate" workflow with visual comparison. Agent must integrate with browser automation MCP servers or accept manual screenshots.

#### Acceptance Criteria
- [ ] Agent file created: plugins/visual-iteration/agents/visual-agent.md
- [ ] Agent defines visual iteration workflow: Load Mock ‚Üí Implement ‚Üí Screenshot ‚Üí Compare ‚Üí Iterate ‚Üí Commit
- [ ] Agent accepts visual mock as target (image file path or drag-drop)
- [ ] Agent implements design in code
- [ ] Agent captures screenshots (via MCP or prompts user)
- [ ] Agent compares result to target with detailed feedback (layout, colors, spacing, typography)
- [ ] Agent iterates 2-3 times minimum for quality
- [ ] Agent commits when user satisfied
- [ ] Agent works with AND without MCP servers (graceful degradation)
- [ ] .gitkeep removed from agents directory

#### Technical Notes
**Visual Comparison Requirements**: AI-based analysis should provide specific, actionable feedback:
- "Submit button is 5px too high"
- "Background color #F0F0F0 should be #FFFFFF"
- "Font size 14px should be 16px"
- "Padding left: 8px should be 12px"

NOT just "doesn't match" - must be detailed and measurable.

**MCP Integration**: Support browser-tools MCP if available, otherwise manual screenshot workflow.

---

### P1-10: Configure visual-iteration MCP Servers

**Status**: Not Started
**Effort**: Medium (3-5 hours)
**Dependencies**: P1-9 (visual agent)
**Spec Reference**: CLAUDE.md line 37 ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 108, 120

#### Description
Configure .mcp.json with browser automation MCP server for automated screenshot capture. Support browser-tools, Puppeteer, or Playwright MCP server if available.

#### Acceptance Criteria
- [ ] .mcp.json contains browser automation MCP server config
- [ ] MCP server: browser-tools, Puppeteer, or Playwright configured
- [ ] MCP configuration includes server endpoints and timeouts
- [ ] Screenshot capture works via MCP commands
- [ ] Browser navigation works via MCP commands
- [ ] Graceful fallback if MCP server unavailable
- [ ] Configuration documented with setup instructions
- [ ] MCP integration tested and working

#### Technical Notes
**Research First**: Check if browser-tools MCP is available in environment (looks like it is based on available tools). If so, configure it. If not, document manual screenshot workflow.

**Available MCP Servers** (from environment):
- mcp__browser-tools__ - APPEARS AVAILABLE
- mcp__playwright__ - APPEARS AVAILABLE

Prioritize browser-tools or playwright for screenshot automation.

---

### P1-11: Implement visual-iteration Slash Commands

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: P1-9 (visual agent)
**Spec Reference**: CLAUDE.md lines 32-41 ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 105, 121

#### Description
Create slash commands for visual iteration workflow: load mock, implement design, capture screenshot, compare, iterate.

#### Acceptance Criteria
- [ ] /load-mock command created - accepts image file path or clipboard
- [ ] /implement-design command created - codes UI from mock
- [ ] /screenshot command created - captures current state (MCP or manual)
- [ ] /compare command created - compares result to target with detailed feedback
- [ ] /iterate command created - adjusts code based on comparison
- [ ] /visual-cycle command created (optional) - full end-to-end workflow
- [ ] All commands in plugins/visual-iteration/commands/
- [ ] Commands registered in plugin.json
- [ ] Commands work with AND without MCP servers
- [ ] .gitkeep removed from commands directory

#### Technical Notes
Commands should degrade gracefully: if MCP unavailable, prompt user to provide screenshots manually. /compare should provide actionable, measurable feedback.

**Expected Lines**: ~1,500-2,000 based on epti command pattern (6 commands, 2,805 lines)

---

### P1-12: Implement visual-iteration Skills

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: None (P0-4 from Sprint 1 complete)
**Spec Reference**: CLAUDE.md lines 32-41 ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 106, 122

#### Description
Create reusable skills for visual iteration: screenshot capture (automated and manual), visual comparison with detailed analysis, design implementation from mock.

#### Acceptance Criteria
- [ ] Skill for screenshot capture (via MCP or manual) created
- [ ] Skill for visual comparison (AI-based detailed analysis) created
- [ ] Skill for design implementation from mock created
- [ ] Skill for iterative refinement based on visual diff created
- [ ] All skills in plugins/visual-iteration/skills/
- [ ] Skills documented with examples
- [ ] Skills work independently of MCP availability
- [ ] .gitkeep removed from skills directory

#### Technical Notes
**Visual Comparison Skill** is the key differentiator. Should analyze:
- **Layout**: Element positions, alignment, grid structure
- **Colors**: Exact hex values, contrast ratios
- **Spacing**: Margins, padding (measured in px)
- **Typography**: Fonts, sizes, weights, line-height
- **Element Positioning**: Absolute measurements when possible

**Expected Lines**: ~1,200-1,500 based on agent-loop skills pattern (4 skills, 1,763 lines)

---

## P2 (Medium) - Quality & Documentation

### P2-1: Create Root README.md

**Status**: Not Started
**Effort**: Medium (2-3 hours)
**Dependencies**: P2-2, P2-3 (plugin READMEs for linking)
**Spec Reference**: General documentation ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 165, 460-463, 619-627

#### Description
Create comprehensive README at repository root explaining marketplace purpose, installation, plugin overview, and quick start guide. Essential for user adoption.

#### Acceptance Criteria
- [ ] README.md created at repository root
- [ ] Marketplace purpose and overview section
- [ ] Installation instructions for Claude Code
- [ ] Section for each of 3 plugins with workflow descriptions
- [ ] Quick start examples for each plugin
- [ ] Links to individual plugin READMEs
- [ ] Requirements section (Claude Code version, MCP servers)
- [ ] License (MIT) and author information (Brandon Fryslie)
- [ ] Troubleshooting section (common issues)

#### Technical Notes
**Structure**:
```markdown
# Claude Code Plugin Marketplace

Personal marketplace of specialized workflow plugins for Claude Code.

## Plugins

### agent-loop - Disciplined Engineering Workflow
Status: ‚úÖ 100% Complete
[Brief description, link to README]

### epti - Test-Driven Development
Status: ‚úÖ 100% Complete (after P1-7, P1-8)
[Brief description, link to README]

### visual-iteration - Visual Design Iteration
Status: üöß In Development
[Brief description]

## Installation
[How to load marketplace in Claude Code]

## Quick Start
[First workflow example]
```

---

### P2-2: Create agent-loop Plugin README

**Status**: Not Started
**Effort**: Small (2 hours)
**Dependencies**: P0-1 (agent-loop testing complete)
**Spec Reference**: General documentation ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 165, 464-469, 613-618

#### Description
Create README in plugins/agent-loop/ with plugin-specific documentation, usage examples, workflow guide. Include test results and real-world examples.

#### Acceptance Criteria
- [ ] README.md created in plugins/agent-loop/
- [ ] Plugin purpose and when to use it
- [ ] Workflow stages explained: Explore ‚Üí Plan ‚Üí Code ‚Üí Commit
- [ ] Available slash commands documented (/explore, /plan, /code, /commit)
- [ ] Agent usage explained
- [ ] Skills documented with parameters
- [ ] Hook behaviors documented (pre-commit, post-code, commit-msg)
- [ ] Complete workflow example end-to-end
- [ ] Tips for best results (e.g., don't skip exploration)

#### Technical Notes
Include examples of typical problems suited for this workflow: implementing new features, architectural changes, complex refactoring. Emphasize importance of exploration and planning before coding.

Reference test results from P0-1 to show real-world usage.

---

### P2-3: Create epti Plugin README

**Status**: Not Started
**Effort**: Small (2 hours)
**Dependencies**: P1-7, P1-8, P2-6 (epti complete and tested)
**Spec Reference**: General documentation ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 165, 470-478, 613-618

#### Description
Create README in plugins/epti/ with TDD workflow documentation, command reference, test-first development guide. Include framework support and test results.

#### Acceptance Criteria
- [ ] README.md created in plugins/epti/
- [ ] TDD workflow explained clearly
- [ ] Available slash commands documented with examples
- [ ] Test-first discipline explained (why tests fail first)
- [ ] Supported test frameworks listed (pytest, jest, go test minimum)
- [ ] Complete TDD cycle example
- [ ] Tips for preventing test overfitting
- [ ] Integration with test runners documented

#### Technical Notes
Emphasize test-first discipline. Explain:
- **Why tests should fail first**: Proves they're testing the right thing
- **How to avoid mock implementations**: Common anti-patterns
- **Benefits of iteration**: Refinement over perfection

Include example: writing tests for a new API endpoint validation.

Reference test results from P2-6 (both Python and JavaScript frameworks).

---

### P2-4: Create visual-iteration Plugin README

**Status**: Not Started
**Effort**: Small (2-3 hours)
**Dependencies**: P1-9, P1-10, P1-11, P1-12 (visual-iteration complete)
**Spec Reference**: General documentation ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 165, 479-486

#### Description
Create README in plugins/visual-iteration/ documenting visual iteration workflow, MCP server setup, screenshot comparison.

#### Acceptance Criteria
- [ ] README.md created in plugins/visual-iteration/
- [ ] Visual iteration workflow explained
- [ ] MCP server setup instructions (browser-tools or Playwright)
- [ ] Available commands documented
- [ ] Manual screenshot fallback explained
- [ ] Visual comparison process documented
- [ ] Complete design iteration example
- [ ] Tips for achieving pixel-perfect results

#### Technical Notes
Include screenshots of the workflow itself if possible. Explain both automated (with MCP) and manual (user provides screenshots) modes.

Example workflow: implementing a login form from Figma mock.

---

### P2-6: Manual Testing Protocol for epti

**Status**: Not Started
**Effort**: Small (2 hours)
**Dependencies**: P1-7, P1-8 (epti 100% complete)
**Spec Reference**: Testing ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 303-311, 605-610

#### Description
Perform manual testing of epti plugin and document results. Verify TDD workflow enforces test-first discipline. Test with multiple frameworks.

#### Acceptance Criteria
- [ ] Test plan created for epti
- [ ] Manual test executed: full TDD cycle (write-tests‚Üíverify‚Üícommit‚Üíimplement‚Üíiterate‚Üícommit)
- [ ] Verify tests written before implementation
- [ ] Verify tests fail before implementation
- [ ] Verify iteration until tests pass
- [ ] Test framework detection verified (pytest and jest minimum)
- [ ] Hooks tested (afterTestWrite, afterCodeChange, beforeCommit)
- [ ] Test results documented with examples
- [ ] Any issues discovered filed as backlog items

#### Technical Notes
**Test Scenario 1** (Python): "Add email and password validation to API endpoint"
**Test Scenario 2** (JavaScript): "Add debounce utility function"

Test with both frameworks to verify framework detection works. Document full TDD cycle for each.

**WHY CRITICAL**: 3,441 lines of epti code (+ skills/hooks) with zero execution evidence. Must verify before declaring complete.

---

### P2-8: Create Validation Script for Plugin Manifests

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: None (can be done anytime)
**Spec Reference**: Quality infrastructure ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 312-314

#### Description
Create validation script that checks all plugin.json files for correctness: validates JSON, checks paths exist, verifies metadata matches marketplace.json.

#### Acceptance Criteria
- [ ] Validation script created: scripts/validate-plugins.py (or .sh)
- [ ] Validates JSON syntax for all plugin.json files
- [ ] Verifies all paths in plugin.json exist in filesystem
- [ ] Checks metadata matches marketplace.json (names, versions, authors)
- [ ] Validates .mcp.json files are parseable JSON
- [ ] Validates hooks.json files are parseable JSON
- [ ] Provides clear error messages with file paths
- [ ] Exit code 0 for success, non-zero for failures
- [ ] Script documented with usage instructions
- [ ] Can be run in CI/CD pipeline or as pre-commit hook

#### Technical Notes
Use Python with json module (prefer uv for dependencies per CLAUDE.md) or shell script with jq. Should be runnable as pre-commit hook.

**Example Checks**:
- `jq . plugin.json` succeeds
- Paths in "agents", "commands", "skills", "hooks" exist
- Names/versions match marketplace.json
- No placeholder values remain

---

### P2-9: Create Integration Tests for Plugin Loading

**Status**: Not Started
**Effort**: Large (6-8 hours)
**Dependencies**: P1-6, P1-11 (all plugins have commands)
**Spec Reference**: Testing infrastructure ‚Ä¢ **Status Reference**: STATUS-2025-10-28-065832.md lines 312-320

#### Description
Create integration tests that verify plugins load correctly, manifests parse, commands register, basic functionality works.

#### Acceptance Criteria
- [ ] Test suite created: tests/integration/
- [ ] Test: marketplace.json loads correctly
- [ ] Test: each plugin loads individually
- [ ] Test: plugin.json files parse correctly
- [ ] Test: commands are registered and accessible
- [ ] Test: agents can be invoked
- [ ] Test: MCP servers initialize (if configured)
- [ ] Test: hooks are registered
- [ ] All tests pass
- [ ] Tests documented with purpose and setup

#### Technical Notes
May require Claude Code test harness or mock environment. Focus on structural validation rather than deep functionality testing. Ensure plugins don't break plugin loader.

**Priority**: Lower than manual testing (P0-1, P2-6) - manual testing provides more immediate value.

---

## P3 (Low) - Enhancements & Optimization

### P3-1: Add Advanced Thinking Modes to agent-loop

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: agent-loop functional (already complete)
**Spec Reference**: CLAUDE.md line 13

#### Description
Enhance agent-loop planning stage to support all thinking modes: "think", "think hard", "think harder", "ultrathink" with documentation on when to use each.

#### Acceptance Criteria
- [ ] Agent supports all thinking levels in planning stage
- [ ] /plan command accepts thinking level parameter
- [ ] Documentation explains when to use each level
- [ ] Examples demonstrate different thinking budgets
- [ ] Thinking level selection guidance provided

#### Technical Notes
Thinking budget allocation: "think" < "think hard" < "think harder" < "ultrathink". Use higher levels for complex architectural decisions, ambiguous requirements, multi-system integrations.

**Optional**: Can defer to post-MVP.

---

### P3-2: Add Test Framework Auto-Detection to epti

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: P1-7, P1-8 (epti functional)
**Spec Reference**: Testing enhancement

#### Description
Enhance epti to automatically detect test framework from project structure and adapt commands accordingly. **NOTE**: This may already be implemented in P1-7 framework-detect.md skill. Reassess after P1-7 complete.

#### Acceptance Criteria
- [ ] Agent detects test framework from project files
- [ ] Supported frameworks: pytest, jest, go test, junit, rspec (5+)
- [ ] Commands adapt to detected framework
- [ ] Test execution uses correct command for framework
- [ ] Documentation lists supported frameworks
- [ ] Fallback to manual framework specification

#### Technical Notes
Detection heuristics: pytest.ini/setup.py ‚Üí pytest, jest.config.js ‚Üí jest, go.mod ‚Üí go test, pom.xml ‚Üí junit, Gemfile with rspec ‚Üí rspec.

**May be redundant** with P1-7 framework-detect skill. Review after P1-7 completion.

---

### P3-3: Add Visual Diff Metrics to visual-iteration

**Status**: Not Started
**Effort**: Large (6-8 hours)
**Dependencies**: P1-9, P1-12 (visual-iteration functional)
**Spec Reference**: Enhancement

#### Description
Enhance visual comparison with quantitative metrics: pixel difference, layout shift, color accuracy scores.

#### Acceptance Criteria
- [ ] Skill for pixel-level comparison created
- [ ] Metric: pixels different (count and percentage)
- [ ] Metric: layout shift measurements (cumulative shift score)
- [ ] Metric: color accuracy (delta-E or RGB distance)
- [ ] Comparison results include both AI analysis and metrics
- [ ] Threshold for "good enough" configurable
- [ ] Documentation explains metrics

#### Technical Notes
Could use image processing libraries (Pillow for Python, sharp for Node). Metrics help quantify progress: "95% match" vs "60% match". Consider structural similarity index (SSIM).

**Optional**: Defer to post-MVP. AI-based analysis in P1-12 should be sufficient for MVP.

---

### P3-4: Create Plugin Marketplace CLI Tool

**Status**: Not Started
**Effort**: Large (10-12 hours)
**Dependencies**: P2-8 (validation script)
**Spec Reference**: Enhancement

#### Description
Create CLI tool for marketplace management: list plugins, validate configurations, run tests, generate new plugin scaffolding.

#### Acceptance Criteria
- [ ] CLI tool created: scripts/marketplace-cli.py
- [ ] Command: list - shows all plugins with status
- [ ] Command: validate - runs validation scripts
- [ ] Command: test - runs test suite
- [ ] Command: new - generates new plugin scaffold
- [ ] Command: doctor - checks environment and dependencies
- [ ] Installable with uv or pip
- [ ] Documentation with all commands

#### Technical Notes
Use Click or Typer for CLI framework. Should be installable in development mode. Use uv for Python packaging per CLAUDE.md guidelines.

**Optional**: Nice-to-have for post-MVP.

---

## Dependency Graph

```
CRITICAL PATH (Sprint 2 Week 2):

Week 2 Day 1-2 (IMMEDIATE):
  P0-1 (test agent-loop) ‚îÄ‚îÄ‚îê
  P0-2 (update CLAUDE.md) ‚îÄ‚îº‚îÄ‚îÄ> UNBLOCKS CONFIDENCE
                           ‚îÇ
  P1-7 (epti skills) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Week 2 Day 3-4:
  P1-7 complete ‚îÄ‚îÄ> P1-8 (epti hooks) ‚îÄ‚îÄ> epti 100% COMPLETE

Week 2 Day 5:
  P1-8 complete ‚îÄ‚îÄ> P2-6 (test epti) ‚îÄ‚îÄ> VERIFY FUNCTIONALITY

Week 2 Day 6-8:
  P0-1, P2-6 complete ‚îÄ‚îÄ> P2-2 (agent-loop README)
                      ‚îÄ‚îÄ> P2-3 (epti README)
                      ‚îÄ‚îÄ> P2-1 (root README)

Sprint 3 (visual-iteration):
  P1-9 (agent) ‚îÄ‚îÄ> P1-10 (MCP) ‚îÄ‚îÄ> P1-11 (commands)
               ‚îÄ‚îÄ> P1-12 (skills)

  P1-9, P1-10, P1-11, P1-12 ‚îÄ‚îÄ> P2-4 (visual README)

Quality Infrastructure:
  P2-8 (validation script) - independent, can run parallel
  P2-9 (integration tests) - after all commands exist

Enhancements (P3):
  All optional, defer to post-MVP
```

---

## Risk Assessment

### CRITICAL Risks (Sprint 2 Week 2)

1. **Untested Implementation - CRITICAL RISK** ‚ö†Ô∏è
   - **Impact**: VERY HIGH - 5,752 lines may not work at all
   - **Evidence**: Zero execution evidence for agent-loop or epti
   - **Mitigation**: Execute P0-1 and P2-6 IMMEDIATELY (Week 2 Day 1-5)
   - **Timeline Impact**: Could discover critical issues requiring rework
   - **Status**: BLOCKING - must resolve before Sprint 2 completion

2. **Outdated Documentation - HIGH RISK** ‚ö†Ô∏è
   - **Impact**: HIGH - Misleads AI assistants and developers
   - **Evidence**: CLAUDE.md claims "skeleton phase" when 58% complete
   - **Mitigation**: Execute P0-2 IMMEDIATELY (Week 2 Day 1, 1 hour)
   - **Timeline Impact**: Minimal - quick fix, high value
   - **Status**: ACTIVELY HARMFUL - fix immediately

### Medium Risks

1. **Test Framework Detection Complexity**
   - **Impact**: Medium - Could delay epti hooks (P1-8)
   - **Mitigation**: Start with 3 frameworks (pytest, jest, go test), expand later
   - **Contingency**: Manual framework specification as fallback

2. **Hook Execution Environment**
   - **Impact**: Medium - Hooks may not trigger as expected
   - **Mitigation**: Test early in P1-4, P1-8 implementation
   - **Contingency**: Document hooks as optional, focus on commands

3. **MCP Server Availability for visual-iteration**
   - **Impact**: Medium - May not have browser automation
   - **Evidence**: browser-tools and playwright MCPs appear available
   - **Mitigation**: Research early in Sprint 3
   - **Contingency**: Manual screenshot workflow (already planned)

### Low Risks

1. **Documentation Effort Underestimated**
   - **Impact**: Low - Can extend sprint slightly
   - **Mitigation**: Use templates, focus on essentials first
   - **Contingency**: Complete critical docs (root README), defer nice-to-haves

---

## Sprint 2 Week 2 Planning

### Sprint 2 Week 2 Goal
**Objective**: Address testing crisis, complete epti to 100%, create essential documentation

**CRITICAL Deliverables**:
- ‚úÖ P0-1: agent-loop manually tested with documented results (DAY 1-2)
- ‚úÖ P0-2: CLAUDE.md updated to reflect current state (DAY 1)
- ‚úÖ P1-7: epti skills implemented (DAY 2-3)
- ‚úÖ P1-8: epti hooks configured, epti 100% complete (DAY 3-4)
- ‚úÖ P2-6: epti manually tested with documented results (DAY 5)
- ‚úÖ P2-2, P2-3: Both plugin READMEs created (DAY 6-7)
- ‚úÖ P2-1: Root README created (DAY 8)

**Estimated Effort**: 15-20 hours
**Items**: 7 work items (2 P0, 2 P1, 3 P2)
**Success Criteria**:
- Testing crisis resolved (both plugins tested)
- Both plugins 100% complete and documented
- Users can install and use marketplace
- Overall completion: 60-65%

### Sprint 3 Goal (Week 3-4)
**Objective**: Complete visual-iteration plugin

**Deliverables**:
- visual-iteration fully implemented (P1-9, P1-10, P1-11, P1-12)
- visual-iteration documented (P2-4)
- Validation scripts (P2-8)
- Integration tests (P2-9) - optional

**Estimated Effort**: 20-28 hours
**Success Criteria**: All 3 plugins functional, MVP complete, ~85% overall completion

---

## Success Metrics

### Sprint 2 Week 2 Success Definition
- [ ] P0-1: agent-loop tested with documented results ‚ö†Ô∏è **CRITICAL**
- [ ] P0-2: CLAUDE.md updated and accurate ‚ö†Ô∏è **CRITICAL**
- [ ] P1-7: epti skills implemented (5 skills)
- [ ] P1-8: epti hooks configured (3 hooks)
- [ ] epti plugin 100% complete (matching agent-loop)
- [ ] P2-6: epti tested with documented results (2 frameworks)
- [ ] P2-1, P2-2, P2-3: All essential READMEs created
- [ ] No .gitkeep files in functional plugins
- [ ] 2 of 3 plugins tested and demonstrable
- [ ] Documentation aligned with reality

### MVP Definition (After Sprint 3)
- [ ] 3 plugins installable without errors
- [ ] Each plugin provides documented workflow
- [ ] Commands execute successfully
- [ ] Basic automation (hooks) works
- [ ] All plugins manually tested with results
- [ ] Root README guides installation and usage
- [ ] Validation scripts prevent broken configs
- [ ] No placeholder/template values remain
- [ ] Documentation current and accurate

---

## Effort Summary

| Priority | Work Items | Estimated Hours |
|----------|-----------|-----------------|
| P0 (CRITICAL) | 2 | 3 hours |
| P1 (Remaining) | 4 | 19-27 hours |
| P2 (High Priority) | 7 | 13-20 hours |
| P3 (Optional) | 4 | 22-31 hours |
| **Total Remaining** | **17** | **57-81 hours** |

**Sprint 2 Week 2 Estimate** (2 P0 + 2 P1 + 3 P2): 15-20 hours
**Sprint 3 Estimate** (4 P1 + 2 P2): 20-28 hours
**Total to MVP**: 35-48 hours remaining

**Progress Tracking**:
- Sprint 1 delivered: ~16-22 hours (7 items)
- Sprint 2 Week 1 delivered: ~16-20 hours (4 items)
- Sprint 2 Week 2 planned: ~15-20 hours (7 items)
- Remaining to MVP after Week 2: ~20-28 hours (Sprint 3)
- **Total MVP effort**: ~67-90 hours (original estimate: 50-72 hours)

---

## Notes

- **TESTING IS PRIORITY #1**: Cannot ship untested code
- **DOCUMENTATION IS PRIORITY #2**: Users cannot use undocumented marketplace
- Sprint 2 Week 1 proved strong implementation velocity
- Sprint 2 Week 2 must prove quality and verification discipline
- Focus on completing epti to same standard as agent-loop
- Defer visual-iteration to Sprint 3 to maintain quality
- P3 enhancements are truly optional - defer until after MVP
- Manual testing provides higher value than automated tests at this stage
- CLAUDE.md accuracy is critical for AI assistant effectiveness

---

## File Provenance

**Source STATUS Report**: STATUS-2025-10-28-065832.md (generated 2025-10-28 06:58:32)
**Source Sprint Plan**: SPRINT-02-2025-10-28-063531.md (generated 2025-10-28 06:35:31)
**Specification**: CLAUDE.md (current version)
**Generated By**: status-planner agent
**Generation Timestamp**: 2025-10-28 07:03:03

**Supersedes**:
- BACKLOG-2025-10-28-063531.md (outdated, pre-Week 1 completion)
- BACKLOG-2025-10-28-062900.md (Sprint 1 backlog)

**Completed Items Removed**:
- P1-3: Implement agent-loop skills ‚úÖ (delivered Sprint 2 Week 1)
- P1-4: Configure agent-loop hooks ‚úÖ (delivered Sprint 2 Week 1)
- P1-5: Implement epti agent ‚úÖ (delivered Sprint 2 Week 1)
- P1-6: Implement epti commands ‚úÖ (delivered Sprint 2 Week 1)

**Critical Updates**:
- P2-5 promoted to P0-1 (URGENT testing)
- P2-7 promoted to P0-2 (URGENT CLAUDE.md update)
- Added detailed STATUS evidence references
- Emphasized testing crisis (5,752 lines untested)
- Emphasized documentation crisis (CLAUDE.md outdated, no READMEs)

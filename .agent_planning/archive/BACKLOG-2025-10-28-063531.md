# Project Backlog: loom99-claude-marketplace

**Generated**: 2025-10-28 06:35:31
**Source STATUS**: STATUS-2025-10-28-063210.md
**Spec Version**: PROJECT_SPEC.md (current)
**Current Completion**: 35% (Sprint 1 Complete)
**Target**: Functional 3-plugin marketplace

---

## Executive Summary

Sprint 1 successfully delivered all P0 foundation items and established the agent-loop plugin as fully functional (60% complete). The marketplace is now installable and demonstrable with one working plugin.

**Sprint 1 Achievements**:
- ✅ All 3 plugins now installable (marketplace.json valid)
- ✅ All configuration files corrected and valid JSON
- ✅ agent-loop plugin functional with agent + 4 commands
- ✅ visual-iteration plugin created and registered
- ✅ 100% of P0 items delivered, 50% of planned P1 items delivered

**Remaining Critical Path**:
1. Complete agent-loop (add skills and hooks) - P1-3, P1-4
2. Implement epti plugin fully (agent, commands, skills, hooks) - P1-5 through P1-8
3. Implement visual-iteration plugin - P1-9 through P1-12
4. Add documentation and testing - P2 items

**Total Remaining Work Items**: 26
**Estimated Effort to MVP**: 35-52 hours (down from 48-69 hours)
**Burn Rate**: Sprint 1 delivered ~16-22 hours of work in 1 week

### Sprint 1 Lessons Learned

**What Went Well**:
- Focused delivery of P0 items prevented scope creep
- agent-loop implementation was thorough and high-quality
- Configuration issues all resolved systematically
- Plugin #3 structure established proactively

**Areas for Improvement**:
- Skills and hooks deferred - need to complete in Sprint 2
- No testing evidence - need testing protocol
- CLAUDE.md not updated during sprint
- Manual verification not documented

**Sprint 2 Adjustments**:
- Add testing gate: verify functionality before marking complete
- Update CLAUDE.md continuously as work completes
- Focus on completing epti to same quality level as agent-loop
- Document manual testing results

---

## P1 (High) - Core Plugin Implementation

### P1-3: Implement agent-loop Skills

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: None (P0-1 complete)
**Spec Reference**: PROJECT_SPEC.md lines 5-17 • **Status Reference**: STATUS-2025-10-28-063210.md lines 53, 212-214

#### Description
Create reusable skills for agent-loop workflow: exploration helpers, planning scaffolding, implementation verification, and git automation. Skills should be invocable and composable.

#### Acceptance Criteria
- [ ] Skill for code exploration/investigation created
- [ ] Skill for plan generation (with thinking triggers) created
- [ ] Skill for implementation verification created
- [ ] Skill for git operations (commit, PR) created
- [ ] All skills in plugins/agent-loop/skills/
- [ ] Skills documented with clear usage examples
- [ ] Skills are reusable across different problem contexts
- [ ] .gitkeep removed from skills directory

#### Technical Notes
Skills complement commands by providing reusable building blocks. Exploration skill could include "find relevant files", "analyze dependencies", etc. Git skill should handle commit message generation, branch management.

---

### P1-4: Configure agent-loop Git Hooks

**Status**: Not Started
**Effort**: Small (2-3 hours)
**Dependencies**: P1-3 (git operations skill)
**Spec Reference**: PROJECT_SPEC.md line 16 • **Status Reference**: STATUS-2025-10-28-063210.md lines 54, 242-246

#### Description
Configure lifecycle hooks in hooks.json to automate git operations and ensure workflow discipline. Hooks should verify plan exists before coding, run verification before commits.

#### Acceptance Criteria
- [ ] hooks.json contains at least 2 hook definitions
- [ ] Hook: pre-code verification (ensure exploration and plan complete)
- [ ] Hook: pre-commit verification (ensure tests pass, docs updated)
- [ ] Hooks integrate properly with workflow stages
- [ ] Hooks provide clear error messages when triggered
- [ ] Hooks are documented in plugin README
- [ ] Hooks tested and confirmed working

#### Technical Notes
Hooks enforce workflow discipline. Consider: `beforeCode` hook checks for plan file, `beforeCommit` hook runs linter/tests, `afterCommit` hook offers PR creation.

---

### P1-5: Implement epti Main Agent (TDD Focus)

**Status**: Not Started
**Effort**: Medium (4-6 hours)
**Dependencies**: None (P0-2, P0-3 complete)
**Spec Reference**: PROJECT_SPEC.md lines 19-30 • **Status Reference**: STATUS-2025-10-28-063210.md lines 77, 89-94

#### Description
Create the main agent for epti plugin implementing test-driven development workflow. Agent must enforce test-first discipline: write tests, verify they fail, implement code, iterate until pass.

#### Acceptance Criteria
- [ ] Agent file created: plugins/epti/agents/tdd-agent.md
- [ ] Agent defines TDD workflow: Write Tests → Verify Fail → Implement → Iterate → Commit
- [ ] Agent explicitly prevents mock implementations during test phase
- [ ] Agent ensures tests fail before implementation starts
- [ ] Agent commits tests separately from implementation
- [ ] Agent drives iteration until all tests pass
- [ ] Agent uses subagents to verify no test-overfitting
- [ ] Agent handles test runner integration (pytest, jest, go test)
- [ ] .gitkeep removed from agents directory

#### Technical Notes
Critical design principle: NEVER write implementation code during test creation phase. Agent should detect test framework from project structure. Use same quality standard as agent-loop (comprehensive, well-structured).

---

### P1-6: Implement epti Slash Commands

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: P1-5 (TDD agent)
**Spec Reference**: PROJECT_SPEC.md lines 19-30 • **Status Reference**: STATUS-2025-10-28-063210.md lines 78, 91

#### Description
Create slash commands for TDD workflow stages. Commands should guide users through disciplined test-first development with clear stage transitions.

#### Acceptance Criteria
- [ ] /write-tests command created - generates tests from requirements
- [ ] /verify-fail command created - runs tests, confirms they fail
- [ ] /implement command created - writes code to pass tests (no test modification)
- [ ] /iterate command created - runs tests, adjusts code, repeats
- [ ] /commit-tests command created - commits tests only
- [ ] /commit-code command created - commits implementation only
- [ ] All commands in plugins/epti/commands/
- [ ] Commands registered in plugin.json
- [ ] Commands enforce TDD discipline (no stage skipping)
- [ ] .gitkeep removed from commands directory

#### Technical Notes
Commands should reference each other for workflow flow: /write-tests → /verify-fail → /implement → /iterate → /commit-code. Consider adding /tdd-full-cycle for complete workflow.

---

### P1-7: Implement epti Skills

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: None (P0-2 complete)
**Spec Reference**: PROJECT_SPEC.md lines 19-30 • **Status Reference**: STATUS-2025-10-28-063210.md lines 79, 92

#### Description
Create reusable skills for TDD workflow: test generation from requirements, test execution and parsing, implementation with test protection, overfitting detection.

#### Acceptance Criteria
- [ ] Skill for test generation from requirements created
- [ ] Skill for test execution and result parsing created
- [ ] Skill for implementation (with test-protection) created
- [ ] Skill for detecting test overfitting created
- [ ] Skill for test framework detection created
- [ ] Skills in plugins/epti/skills/
- [ ] Skills documented with examples
- [ ] Skills work with multiple test frameworks (pytest, jest, go test minimum)
- [ ] .gitkeep removed from skills directory

#### Technical Notes
Overfitting detection skill is critical: should use subagents to verify implementation solves actual problem, not just satisfies tests. Test framework detection should check for pytest.ini, jest.config.js, go.mod, etc.

---

### P1-8: Configure epti Test Runner Hooks

**Status**: Not Started
**Effort**: Small (2-3 hours)
**Dependencies**: P1-7 (test execution skill)
**Spec Reference**: PROJECT_SPEC.md line 27 • **Status Reference**: STATUS-2025-10-28-063210.md lines 80, 93

#### Description
Configure hooks to automatically run tests after code changes, prevent commits when tests fail, and enforce TDD discipline.

#### Acceptance Criteria
- [ ] hooks.json contains test automation hooks
- [ ] Hook: post-code execution runs test suite
- [ ] Hook: pre-commit blocks if tests fail
- [ ] Hook: post-test-write verifies tests fail before implementation
- [ ] Hooks detect test framework automatically
- [ ] Hook failures provide clear error messages
- [ ] Hooks are documented
- [ ] Hooks tested and confirmed working

#### Technical Notes
Test framework detection order: Look for config files (pytest.ini, jest.config.js), then package files (package.json with jest, go.mod), then file patterns (*_test.py, *.test.js, *_test.go).

---

### P1-9: Implement visual-iteration Main Agent

**Status**: Not Started
**Effort**: Large (6-8 hours)
**Dependencies**: None (P0-4, P0-5 complete)
**Spec Reference**: PROJECT_SPEC.md lines 32-41 • **Status Reference**: STATUS-2025-10-28-063210.md lines 104, 119-123

#### Description
Create agent for visual-iteration plugin implementing "Write code → Screenshot result → Iterate" workflow with visual comparison. Agent must integrate with browser automation or accept manual screenshots.

#### Acceptance Criteria
- [ ] Agent file created: plugins/visual-iteration/agents/visual-agent.md
- [ ] Agent defines visual iteration workflow: Load Mock → Implement → Screenshot → Compare → Iterate → Commit
- [ ] Agent accepts visual mock as target (image file path or drag-drop)
- [ ] Agent implements design in code
- [ ] Agent captures screenshots (via MCP or prompts user)
- [ ] Agent compares result to target with detailed feedback
- [ ] Agent iterates 2-3 times minimum for quality
- [ ] Agent commits when user satisfied
- [ ] Agent works with and without MCP servers
- [ ] .gitkeep removed from agents directory

#### Technical Notes
Visual comparison should be AI-based: analyze layout, colors, spacing, typography, element positioning. Provide specific feedback: "button is 5px too high, background color #F0F0F0 should be #FFFFFF". Support both automated (Puppeteer MCP) and manual modes.

---

### P1-10: Configure visual-iteration MCP Servers

**Status**: Not Started
**Effort**: Medium (3-5 hours)
**Dependencies**: P1-9 (visual agent)
**Spec Reference**: PROJECT_SPEC.md line 37 • **Status Reference**: STATUS-2025-10-28-063210.md lines 108, 120

#### Description
Configure .mcp.json with browser automation MCP server for automated screenshot capture. Support Puppeteer or Playwright MCP server if available.

#### Acceptance Criteria
- [ ] .mcp.json contains browser automation MCP server config
- [ ] MCP server: Puppeteer or Playwright configured
- [ ] MCP configuration includes server endpoints and timeouts
- [ ] Screenshot capture works via MCP commands
- [ ] Browser navigation works via MCP commands
- [ ] Graceful fallback if MCP server unavailable
- [ ] Configuration documented with setup instructions
- [ ] MCP integration tested and working

#### Technical Notes
Research available MCP servers first. If Puppeteer MCP exists, use it. If not, document manual screenshot workflow. Consider browser-tools MCP if available in environment.

---

### P1-11: Implement visual-iteration Slash Commands

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: P1-9 (visual agent)
**Spec Reference**: PROJECT_SPEC.md lines 32-41 • **Status Reference**: STATUS-2025-10-28-063210.md lines 105, 121

#### Description
Create slash commands for visual iteration workflow: load mock, implement design, capture screenshot, compare, iterate.

#### Acceptance Criteria
- [ ] /load-mock command created - accepts image file path or clipboard
- [ ] /implement-design command created - codes UI from mock
- [ ] /screenshot command created - captures current state (MCP or manual)
- [ ] /compare command created - compares result to target with detailed feedback
- [ ] /iterate command created - adjusts code based on comparison
- [ ] /visual-cycle command created - full end-to-end workflow
- [ ] Commands in plugins/visual-iteration/commands/
- [ ] Commands registered in plugin.json
- [ ] Commands work with and without MCP servers
- [ ] .gitkeep removed from commands directory

#### Technical Notes
Commands should degrade gracefully: if MCP unavailable, prompt user to provide screenshots manually. /compare should provide actionable feedback, not just "doesn't match".

---

### P1-12: Implement visual-iteration Skills

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: None (P0-4 complete)
**Spec Reference**: PROJECT_SPEC.md lines 32-41 • **Status Reference**: STATUS-2025-10-28-063210.md lines 106, 122

#### Description
Create reusable skills for visual iteration: screenshot capture (automated and manual), visual comparison with detailed analysis, design implementation from mock.

#### Acceptance Criteria
- [ ] Skill for screenshot capture (via MCP or manual) created
- [ ] Skill for visual comparison (AI-based detailed analysis) created
- [ ] Skill for design implementation from mock created
- [ ] Skill for iterative refinement based on visual diff created
- [ ] Skills in plugins/visual-iteration/skills/
- [ ] Skills documented with examples
- [ ] Skills work independently of MCP availability
- [ ] .gitkeep removed from skills directory

#### Technical Notes
Visual comparison skill is the key differentiator. Should analyze: layout (element positions, alignment), colors (exact hex values), spacing (margins, padding), typography (fonts, sizes, weights), element positioning. Provide measurements when possible.

---

## P2 (Medium) - Quality & Documentation

### P2-1: Create Root README.md

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: P1-2, P1-6, P1-11 (all commands implemented)
**Spec Reference**: General documentation • **Status Reference**: STATUS-2025-10-28-063210.md lines 165, 460-463

#### Description
Create comprehensive README at repository root explaining marketplace purpose, installation, plugin overview, and quick start guide.

#### Acceptance Criteria
- [ ] README.md created at repository root
- [ ] Marketplace purpose and overview section
- [ ] Installation instructions for Claude Code
- [ ] Section for each of 3 plugins with workflow descriptions
- [ ] Quick start examples for each plugin
- [ ] Links to individual plugin READMEs (when they exist)
- [ ] Requirements section (Claude Code version, MCP servers)
- [ ] License (MIT) and author information
- [ ] Troubleshooting section (common issues)

#### Technical Notes
Explain how to install marketplace from Claude Code, load individual plugins, and when to use each workflow. Include example scenarios: "Use agent-loop for new features, epti for refactoring, visual-iteration for UI work."

---

### P2-2: Create agent-loop Plugin README

**Status**: Not Started
**Effort**: Small (2-3 hours)
**Dependencies**: P1-1, P1-2, P1-3, P1-4 (agent-loop complete)
**Spec Reference**: General documentation • **Status Reference**: STATUS-2025-10-28-063210.md lines 165, 464-469

#### Description
Create README in plugins/agent-loop/ with plugin-specific documentation, usage examples, workflow guide.

#### Acceptance Criteria
- [ ] README.md created in plugins/agent-loop/
- [ ] Plugin purpose and when to use it
- [ ] Workflow stages explained: Explore → Plan → Code → Commit
- [ ] Available slash commands documented (/explore, /plan, /code, /commit)
- [ ] Agent usage explained
- [ ] Skills documented with parameters
- [ ] Hook behaviors documented
- [ ] Complete workflow example end-to-end
- [ ] Tips for best results (e.g., don't skip exploration)

#### Technical Notes
Include examples of typical problems suited for this workflow: implementing new features, architectural changes, complex refactoring. Emphasize importance of exploration and planning before coding.

---

### P2-3: Create epti Plugin README

**Status**: Not Started
**Effort**: Small (2-3 hours)
**Dependencies**: P1-5, P1-6, P1-7, P1-8 (epti complete)
**Spec Reference**: General documentation • **Status Reference**: STATUS-2025-10-28-063210.md lines 165, 470-478

#### Description
Create README in plugins/epti/ with TDD workflow documentation, command reference, test-first development guide.

#### Acceptance Criteria
- [ ] README.md created in plugins/epti/
- [ ] TDD workflow explained clearly
- [ ] Available slash commands documented with examples
- [ ] Test-first discipline explained (why tests fail first)
- [ ] Supported test frameworks listed (pytest, jest, go test)
- [ ] Complete TDD cycle example
- [ ] Tips for preventing test overfitting
- [ ] Integration with test runners documented

#### Technical Notes
Emphasize test-first discipline. Explain why tests should fail first (proves they're testing the right thing), how to avoid mock implementations, benefits of iteration. Include example: writing tests for a new API endpoint.

---

### P2-4: Create visual-iteration Plugin README

**Status**: Not Started
**Effort**: Small (2-3 hours)
**Dependencies**: P1-9, P1-10, P1-11, P1-12 (visual-iteration complete)
**Spec Reference**: General documentation • **Status Reference**: STATUS-2025-10-28-063210.md lines 165, 479-486

#### Description
Create README in plugins/visual-iteration/ documenting visual iteration workflow, MCP server setup, screenshot comparison.

#### Acceptance Criteria
- [ ] README.md created in plugins/visual-iteration/
- [ ] Visual iteration workflow explained
- [ ] MCP server setup instructions (Puppeteer or browser-tools)
- [ ] Available commands documented
- [ ] Manual screenshot fallback explained
- [ ] Visual comparison process documented
- [ ] Complete design iteration example
- [ ] Tips for achieving pixel-perfect results

#### Technical Notes
Include screenshots of the workflow itself if possible. Explain both automated (with MCP) and manual (user provides screenshots) modes. Example: implementing a login form from Figma mock.

---

### P2-5: Manual Testing Protocol for agent-loop

**Status**: Not Started
**Effort**: Small (2 hours)
**Dependencies**: P1-1, P1-2 (agent-loop functional)
**Spec Reference**: Testing • **Status Reference**: STATUS-2025-10-28-063210.md lines 294-302

#### Description
Perform manual testing of agent-loop plugin and document results. Verify workflow executes correctly end-to-end.

#### Acceptance Criteria
- [ ] Test plan created for agent-loop
- [ ] Manual test executed: full explore→plan→code→commit workflow
- [ ] Each command (/explore, /plan, /code, /commit) tested individually
- [ ] Agent guidance verified at each stage
- [ ] Workflow transitions tested
- [ ] Git operations verified
- [ ] Test results documented
- [ ] Any issues discovered filed as backlog items

#### Technical Notes
Use a simple test scenario: "Add a helper function to calculate date differences." Execute full workflow, document each step, note any issues or unclear guidance.

---

### P2-6: Manual Testing Protocol for epti

**Status**: Not Started
**Effort**: Small (2 hours)
**Dependencies**: P1-5, P1-6 (epti functional)
**Spec Reference**: Testing • **Status Reference**: STATUS-2025-10-28-063210.md lines 303-311

#### Description
Perform manual testing of epti plugin and document results. Verify TDD workflow enforces test-first discipline.

#### Acceptance Criteria
- [ ] Test plan created for epti
- [ ] Manual test executed: full TDD cycle
- [ ] Verify tests written before implementation
- [ ] Verify tests fail before implementation
- [ ] Verify iteration until tests pass
- [ ] Test framework detection verified
- [ ] Test results documented
- [ ] Any issues discovered filed as backlog items

#### Technical Notes
Use test scenario: "Add validation to an API endpoint." Write tests first, verify they fail, implement, iterate. Test with at least 2 frameworks (e.g., Python with pytest, JavaScript with jest).

---

### P2-7: Update CLAUDE.md to Reflect Current State

**Status**: Not Started
**Effort**: Small (1-2 hours)
**Dependencies**: P1-5, P1-6 (both main plugins functional)
**Spec Reference**: Documentation accuracy • **Status Reference**: STATUS-2025-10-28-063210.md lines 165-177, 206-209

#### Description
Update CLAUDE.md to reflect actual implementation state. Remove outdated "skeleton/placeholder" language, update plugin descriptions.

#### Acceptance Criteria
- [ ] Line 85 "skeleton/placeholder phase" statement removed
- [ ] Plugin status updated from "Early development" to "Implemented" or "In Progress"
- [ ] Document agent-loop as functional with agent + 4 commands
- [ ] Document epti status accurately
- [ ] Document visual-iteration status accurately
- [ ] Update Current Plugins section with actual command names
- [ ] Add usage examples or workflow descriptions
- [ ] Ensure all paths and references are correct

#### Technical Notes
CLAUDE.md is the project instruction file for Claude Code. Keep it concise but accurate. Focus on architectural overview and development guidance, not detailed API docs (that belongs in READMEs).

---

### P2-8: Create Validation Script for Plugin Manifests

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: None (can be done anytime)
**Spec Reference**: Quality infrastructure • **Status Reference**: STATUS-2025-10-28-063210.md lines 312-314

#### Description
Create validation script that checks all plugin.json files for correctness: validates JSON, checks paths exist, verifies metadata matches marketplace.json.

#### Acceptance Criteria
- [ ] Validation script created: scripts/validate-plugins.py (or .sh)
- [ ] Validates JSON syntax for all plugin.json files
- [ ] Verifies all paths in plugin.json exist in filesystem
- [ ] Checks metadata matches marketplace.json (names, versions, authors)
- [ ] Validates .mcp.json files are parseable JSON
- [ ] Validates hooks.json files are parseable JSON
- [ ] Provides clear error messages with file paths
- [ ] Exit code 0 for success, non-zero for failures
- [ ] Script documented with usage instructions
- [ ] Can be run in CI/CD pipeline

#### Technical Notes
Use Python with json module or shell script with jq. Should be runnable as pre-commit hook. Consider using uv for Python dependencies if needed.

---

### P2-9: Create Integration Tests for Plugin Loading

**Status**: Not Started
**Effort**: Large (6-8 hours)
**Dependencies**: P1-2, P1-6, P1-11 (all plugins have commands)
**Spec Reference**: Testing infrastructure • **Status Reference**: STATUS-2025-10-28-063210.md lines 312-320

#### Description
Create integration tests that verify plugins load correctly, manifests parse, commands register, basic functionality works.

#### Acceptance Criteria
- [ ] Test suite created: tests/integration/
- [ ] Test: marketplace.json loads correctly
- [ ] Test: each plugin loads individually
- [ ] Test: plugin.json files parse correctly
- [ ] Test: commands are registered and accessible
- [ ] Test: agents can be invoked
- [ ] Test: MCP servers initialize (if configured)
- [ ] Test: hooks are registered
- [ ] All tests pass
- [ ] Tests documented with purpose and setup

#### Technical Notes
May require Claude Code test harness or mock environment. Focus on structural validation rather than deep functionality testing. Ensure plugins don't break plugin loader.

---

## P3 (Low) - Enhancements & Optimization

### P3-1: Add Advanced Thinking Modes to agent-loop

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: P1-1, P1-2 (agent-loop functional)
**Spec Reference**: PROJECT_SPEC.md line 13

#### Description
Enhance agent-loop planning stage to support all thinking modes: "think", "think hard", "think harder", "ultrathink" with documentation on when to use each.

#### Acceptance Criteria
- [ ] Agent supports all thinking levels in planning stage
- [ ] /plan command accepts thinking level parameter
- [ ] Documentation explains when to use each level
- [ ] Examples demonstrate different thinking budgets
- [ ] Thinking level selection guidance provided

#### Technical Notes
Thinking budget allocation: "think" < "think hard" < "think harder" < "ultrathink". Use higher levels for complex architectural decisions, ambiguous requirements, multi-system integrations.

---

### P3-2: Add Test Framework Auto-Detection to epti

**Status**: Not Started
**Effort**: Medium (3-4 hours)
**Dependencies**: P1-5, P1-8 (epti functional)
**Spec Reference**: Testing enhancement

#### Description
Enhance epti to automatically detect test framework from project structure and adapt commands accordingly.

#### Acceptance Criteria
- [ ] Agent detects test framework from project files
- [ ] Supported frameworks: pytest, jest, go test, junit, rspec
- [ ] Commands adapt to detected framework
- [ ] Test execution uses correct command for framework
- [ ] Documentation lists supported frameworks
- [ ] Fallback to manual framework specification

#### Technical Notes
Detection heuristics: pytest.ini/setup.py → pytest, jest.config.js → jest, go.mod → go test, pom.xml → junit, Gemfile with rspec → rspec.

---

### P3-3: Add Visual Diff Metrics to visual-iteration

**Status**: Not Started
**Effort**: Large (6-8 hours)
**Dependencies**: P1-9, P1-12 (visual-iteration functional)
**Spec Reference**: Enhancement

#### Description
Enhance visual comparison with quantitative metrics: pixel difference, layout shift, color accuracy scores.

#### Acceptance Criteria
- [ ] Skill for pixel-level comparison created
- [ ] Metric: pixels different (count and percentage)
- [ ] Metric: layout shift measurements
- [ ] Metric: color accuracy (delta-E or similar)
- [ ] Comparison results include both AI analysis and metrics
- [ ] Threshold for "good enough" configurable
- [ ] Documentation explains metrics

#### Technical Notes
Could use image processing libraries (Pillow, sharp). Metrics help quantify progress: "95% match" vs "60% match". Consider structural similarity index (SSIM).

---

### P3-4: Create Plugin Marketplace CLI Tool

**Status**: Not Started
**Effort**: Large (10-12 hours)
**Dependencies**: P2-8 (validation script)
**Spec Reference**: Enhancement

#### Description
Create CLI tool for marketplace management: list plugins, validate configurations, run tests, generate new plugin scaffolding.

#### Acceptance Criteria
- [ ] CLI tool created: scripts/marketplace-cli.py
- [ ] Command: list - shows all plugins with status
- [ ] Command: validate - runs validation scripts
- [ ] Command: test - runs test suite
- [ ] Command: new - generates new plugin scaffold
- [ ] Command: doctor - checks environment and dependencies
- [ ] Installable with uv or pip
- [ ] Documentation with all commands

#### Technical Notes
Use Click or Typer for CLI framework. Should be installable in development mode. Use uv for Python packaging per CLAUDE.md guidelines.

---

## Dependency Graph

```
Sprint 2 Focus (P1 Completion):
  agent-loop completion:
    P1-3 (skills) ──> P1-4 (hooks)

  epti implementation:
    P1-5 (agent) ──> P1-6 (commands)
                 ──> P1-7 (skills) ──> P1-8 (hooks)

Documentation (Early):
  P1-3, P1-4 ──> P2-2 (agent-loop README)
                 P2-5 (agent-loop testing)

  P1-5, P1-6 ──> P2-6 (epti testing)

  P1-6, P1-7, P1-8 ──> P2-3 (epti README)

  P2-2, P2-3 ──> P2-1 (root README)

Sprint 3+ Focus:
  visual-iteration:
    P1-9 (agent) ──> P1-10 (MCP) ──> P1-11 (commands)
                 ──> P1-12 (skills)

  P1-9, P1-10, P1-11, P1-12 ──> P2-4 (visual-iteration README)

Quality:
  P2-8 (validation script) - independent
  P2-7 (CLAUDE.md update) - after P1-5, P1-6
  P2-9 (integration tests) - after all P1 commands

Enhancements (P3):
  All optional, can be done anytime after dependencies complete
```

---

## Risk Assessment

### High-Risk Items

1. **P1-10: MCP Server Configuration** - Unknown if browser automation MCP server exists
   - **Mitigation**: Research available MCP servers early; fall back to manual screenshots
   - **Contingency**: Document manual workflow as primary, MCP as optional enhancement

2. **P2-9: Integration Tests** - Unclear if Claude Code provides test harness
   - **Mitigation**: Start with JSON validation tests, expand as tooling discovered
   - **Contingency**: Use manual testing protocols (P2-5, P2-6) as primary verification

### Medium-Risk Items

1. **Test Framework Detection (P1-7, P1-8)** - May not cover all frameworks
   - **Mitigation**: Start with 3 most common (pytest, jest, go test)
   - **Contingency**: Provide manual framework specification option

2. **Visual Comparison Quality (P1-9, P1-12)** - AI-based analysis may be inconsistent
   - **Mitigation**: Provide clear examples and iteration guidance
   - **Contingency**: Add quantitative metrics in P3-3

### Blockers to Watch

- MCP server availability for visual-iteration plugin
- Test runner integration complexities
- Hook execution environment limitations

---

## Sprint 2 Planning Recommendations

### Sprint 2 Goal (Week 1-2)
**Objective**: Complete agent-loop and epti plugins to same quality level

**Deliverables**:
- agent-loop skills and hooks implemented (P1-3, P1-4)
- epti fully implemented (agent, commands, skills, hooks) (P1-5, P1-6, P1-7, P1-8)
- Both plugins manually tested (P2-5, P2-6)
- Documentation for both plugins (P2-2, P2-3)
- Root README with installation guide (P2-1)
- CLAUDE.md updated (P2-7)

**Estimated Effort**: 20-28 hours
**Items**: 11 work items (6 P1, 5 P2)
**Success Criteria**: 2 of 3 plugins fully functional and documented, 60-65% overall completion

### Sprint 3 Goal (Week 3-4)
**Objective**: Complete visual-iteration plugin

**Deliverables**:
- visual-iteration fully implemented (P1-9, P1-10, P1-11, P1-12)
- visual-iteration documented (P2-4)
- Validation scripts (P2-8)
- Integration tests (P2-9)

**Estimated Effort**: 20-26 hours
**Success Criteria**: All 3 plugins functional, MVP complete, ~85% overall completion

---

## Success Metrics

### Sprint 2 Success Definition
- [ ] agent-loop has skills and hooks implemented
- [ ] epti plugin fully functional (agent, commands, skills, hooks)
- [ ] Both plugins manually tested with documented results
- [ ] Both plugins have README documentation
- [ ] Root README created with installation guide
- [ ] CLAUDE.md updated to reflect current state
- [ ] No placeholder or .gitkeep files in functional plugins
- [ ] 2 of 3 plugins demonstrable end-to-end

### MVP Definition (After Sprint 3)
- [ ] 3 plugins installable without errors
- [ ] Each plugin provides documented workflow
- [ ] Commands execute successfully
- [ ] Basic automation (hooks) works
- [ ] Root README guides installation and usage
- [ ] Validation scripts prevent broken configs
- [ ] No placeholder/template values remain

---

## Effort Summary

| Priority | Work Items | Estimated Hours |
|----------|-----------|-----------------|
| P1 (Remaining) | 10 | 38-55 hours |
| P2 (High Priority) | 9 | 21-32 hours |
| P3 (Optional) | 4 | 22-31 hours |
| **Total Remaining** | **23** | **81-118 hours** |

**Sprint 2 Estimate** (6 P1 + 5 P2): 20-28 hours
**Sprint 3 Estimate** (4 P1 + 4 P2): 20-26 hours
**Total to MVP**: 40-54 hours remaining

**Progress Update**:
- Sprint 1 delivered: ~16-22 hours
- Remaining to MVP: ~40-54 hours
- Total MVP effort: ~56-76 hours (original estimate: 50-72 hours) ✅

---

## Notes

- Sprint 1 demonstrated solid velocity: 7 items delivered in 1 week
- Focus Sprint 2 on completing epti to same quality as agent-loop
- Defer visual-iteration to Sprint 3 to maintain quality
- Continuous documentation updates prevent drift
- Testing protocols ensure functionality before marking complete
- P3 enhancements are truly optional - defer until after MVP
